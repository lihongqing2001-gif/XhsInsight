# -*- coding: utf-8 -*-
from xhs_ai_wrapper import XHS_Wrapper
import json

def test_spider():
    print("ğŸš€ å¼€å§‹æµ‹è¯•çˆ¬è™«...")
    
    try:
        # 1. åˆå§‹åŒ–
        # å®ƒä¼šè‡ªåŠ¨å» Spider_XHS-master/.env æ‰¾ Cookie
        spider = XHS_Wrapper()
        print("âœ… åˆå§‹åŒ–æˆåŠŸï¼")
        
    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶é”™è¯¯: {e}")
        return
    except ValueError as e:
        print(f"âŒ é…ç½®é”™è¯¯: {e}")
        return
    except Exception as e:
        print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
        return

    # 2. æµ‹è¯•æœç´¢åŠŸèƒ½
    keyword = "çŒ«å’ª"
    print(f"\nğŸ” æ­£åœ¨æµ‹è¯•æœç´¢å…³é”®è¯: [{keyword}] ...")
    
    search_res = spider.search_notes(keyword, limit=3)
    
    if search_res['status'] == 'success':
        notes = search_res['data']
        print(f"âœ… æœç´¢æµ‹è¯•é€šè¿‡ï¼æ‰¾åˆ°äº† {len(notes)} æ¡ç¬”è®°ï¼š")
        
        for i, note in enumerate(notes):
            print(f"   {i+1}. {note['title']} (ID: {note['id']})")
            
        # 3. æµ‹è¯•è·å–è¯¦æƒ…åŠŸèƒ½ (å¦‚æœæœç´¢åˆ°äº†ç¬”è®°)
        if len(notes) > 0:
            first_url = notes[0]['link']
            print(f"\nğŸ“– æ­£åœ¨æµ‹è¯•è·å–å•ç¯‡ç¬”è®°è¯¦æƒ…: {first_url}")
            
            detail_res = spider.get_note_detail(first_url)
            
            if detail_res['status'] == 'success':
                data = detail_res['data']
                print("âœ… è¯¦æƒ…æµ‹è¯•é€šè¿‡ï¼")
                print(f"   æ ‡é¢˜: {data['title']}")
                print(f"   ç‚¹èµ: {data['stats']['liked_count']}")
                print(f"   å›¾ç‰‡æ•°: {len(data['images'])}")
            else:
                print(f"âŒ è¯¦æƒ…æµ‹è¯•å¤±è´¥: {detail_res['message']}")
    else:
        print(f"âŒ æœç´¢æµ‹è¯•å¤±è´¥: {search_res['message']}")
        # å¸¸è§é”™è¯¯åˆ†æ
        if "ç™»å½•" in str(search_res['message']):
            print("\nâš ï¸ è¯Šæ–­: Cookie å¯èƒ½å·²è¿‡æœŸæˆ–æ— æ•ˆï¼Œè¯·é‡æ–°å¤åˆ¶ web_session åˆ° .env æ–‡ä»¶ä¸­ã€‚")

if __name__ == "__main__":
    test_spider()
